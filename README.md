# Desafio Structure data from PDF - Enter AI Fellowship - Ian Klein

> Sistema inteligente de extra√ß√£o de dados estruturados de PDFs usando IA com interface web moderna e cache sem√¢ntico

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://www.python.org/)
[![React](https://img.shields.io/badge/React-18-61DAFB.svg)](https://reactjs.org/)
[![TypeScript](https://img.shields.io/badge/TypeScript-5-3178C6.svg)](https://www.typescriptlang.org/)
[![Flask](https://img.shields.io/badge/Flask-3.0-000000.svg)](https://flask.palletsprojects.com/)
[![OpenAI](https://img.shields.io/badge/OpenAI-GPT--4--mini-412991.svg)](https://openai.com/)

---

## üéØ Como Usar

Este projeto √© uma aplica√ß√£o **full-stack completa** com backend Flask e frontend React. O Flask serve tanto a API quanto a interface web.

**Para rodar localmente:**
1. Execute os comandos do TL;DR abaixo
2. Acesse `http://localhost:5000` no seu navegador
3. O frontend estar√° dispon√≠vel automaticamente (j√° compilado em `frontend/dist/`)

O servidor Flask entrega a interface React e processa as requisi√ß√µes de extra√ß√£o de PDF. Sem necessidade de rodar frontend separadamente!

---

## ‚ö° TL;DR

```bash
# 1. Setup
python -m venv venv && .\venv\Scripts\Activate.ps1
pip install -r requirements.txt && pip install httpx==0.27.0 httpcore==1.0.5

# 2. Configurar vari√°veis de ambiente
cp .env.example .env
# Edite o arquivo .env e adicione sua OPENAI_API_KEY

# 3. Build Frontend
cd frontend
cp .env.example .env  # Configurar URL da API (j√° vem com localhost:5000)
npm install && npm run build
cd ..

# 4. Run
python app.py
# Acesse: http://localhost:5000
```

### üîë Vari√°veis de Ambiente Necess√°rias

**Backend (`.env` na raiz):**
```bash
OPENAI_API_KEY=sk-your-openai-api-key-here
```

**Frontend (`frontend/.env`):**
```bash
VITE_API_URL=http://localhost:5000
```

**O que faz:** Extrai dados estruturados de PDFs usando GPT-5-mini com cache inteligente. Interface web moderna com drag & drop, SSE real-time e feedback completo de custos/tokens.

---

## üìä Optimization Journey - Challenge Results

Durante o desenvolvimento, testamos m√∫ltiplas estrat√©gias de otimiza√ß√£o para atingir os requisitos do desafio: **<10s por documento** e **100% de acur√°cia**.

### Resultados Comparativos

| Fase      | Tempo M√©dio | Acur√°cia | Campos Corretos | T√©cnica Principal                        | Status |
|-----------|-------------|----------|-----------------|------------------------------------------|--------|
| **FASE 1**    | 13.89s      | 94.59%   | 35/37           | Prompt optimization (40% token reduction) | ‚úÖ Est√°vel |
| **FASE 2A**   | 20.78s      | 83.78%   | 31/37           | Pattern matching agressivo               | ‚ùå Falhou |
| **FASE 2B**   | 13.89s      | 94.59%   | 35/37           | Date hints + conservative extraction     | ‚úÖ **MELHOR** |
| **FASE 3**    | 16.25s      | 94.59%   | 35/37           | Template matching via fingerprinting     | ‚ùå N√£o detectou similaridade |

### O Que Funcionou ‚úÖ

1. **Prompt Optimization (FASE 1)**
   - Reduziu system prompt de ~400 para ~250 tokens (40% redu√ß√£o)
   - Manteve instru√ß√µes cr√≠ticas: regras de formata√ß√£o, dicas estruturais, exemplos compactos
   - Acur√°cia mantida em 94.59% com tempo de 13.89s

2. **Few-Shot Learning com Cache Sem√¢ntico**
   - Documentos 2+ com exemplos cached: m√©dia de ~10.16s
   - Primeiro documento sem exemplos: ~24s
   - Sistema aprende com extra√ß√µes anteriores usando embeddings (sentence-transformers)

3. **Date Extraction Hints (FASE 2B)**
   - Extraiu TODAS as datas do documento via regex
   - Passou lista ao LLM: "H√° 2 datas no documento: 05/09/2025, 12/10/2025"
   - **Resultado:** Corrigiu erro cr√≠tico de `data_verncimento` (antes extra√≠a data errada)

4. **PyMuPDF Local Extraction**
   - Extra√ß√£o de texto local (custo ZERO)
   - Performance 35x superior vs API-based extraction
   - Base s√≥lida para pattern matching conservador

### O Que N√£o Funcionou ‚ùå

1. **Pattern Matching Agressivo (FASE 2A)**
   - Tentativa: Extrair campos estruturados (CPF, CEP, telefone, n√∫meros) via regex antes do LLM
   - **Problema:** Confundiu campos similares (CEP de 8 d√≠gitos como telefone, n√∫meros aleat√≥rios como parcelas)
   - **Impacto:** Acur√°cia caiu de 94.59% ‚Üí 83.78%, tempo aumentou para 20.78s
   - **Decis√£o:** Rollback completo, manter apenas extra√ß√£o de datas m√∫ltiplas

2. **Template Matching via Fingerprinting (FASE 3)**
   - Tentativa: Detectar documentos similares (mesmo template OAB) e reusar resultado sem chamar LLM
   - **Problema:** Fingerprint baseado nos primeiros 500 caracteres inclu√≠a nome do titular, diferente em cada documento
   - **Impacto:** NENHUM template detectado entre 3 carteiras OAB id√™nticas, tempo aumentou para 16.25s
   - **Aprendizado:** Fingerprinting estrutural requer an√°lise mais sofisticada (ignorar campos vari√°veis)

3. **Token Reduction Attempts**
   - Testamos reduzir `max_completion_tokens` de 1500 ‚Üí 600
   - **Problema:** GPT-5-mini usa 800-1400 tokens para reasoning interno (n√£o control√°vel)
   - **Impacto:** Respostas vazias com `finish_reason='length'`
   - **Decis√£o:** Manter 1500 tokens (recomenda√ß√£o do usu√°rio)

### Limita√ß√µes T√©cnicas Descobertas ‚ö†Ô∏è

1. **GPT-5 Reasoning Tokens (N√£o Control√°vel)**
   - Modelo gasta 800-1400 tokens em reasoning interno antes de gerar resposta
   - Isso adiciona ~7-12s por requisi√ß√£o (tempo de infer√™ncia m√≠nimo)
   - **Conclus√£o:** Dif√≠cil atingir <10s consistente no primeiro documento sem cache

2. **Variabilidade de Tempo**
   - Primeiro documento: 19-27s (sem exemplos cached)
   - Documentos seguintes: 10-16s (com few-shot learning)
   - Cache hit: <0.01s (extra√ß√£o instant√¢nea)

3. **Campos Persistentemente Problem√°ticos**
   - `total_de_parcelas`: Valor "96" vis√≠vel na imagem mas n√£o extra√≠do (null)
   - `produto`: Extrai "0 CONSIGNADO" ao inv√©s de "CONSIGNADO"
   - Pattern matching falhou, LLM com texto completo tamb√©m falhou

### Current Best Result üèÜ

**FASE 2B** √© atualmente a melhor vers√£o:

```
‚úÖ Acur√°cia: 94.59% (35/37 campos corretos)
‚úÖ Tempo m√©dio: 13.89s (documentos 2+ com cache: ~10.16s)
‚úÖ Custo m√©dio: $0.001739 USD (~R$ 0.0093 BRL)
‚úÖ Cache funcional: Few-shot learning ativo
‚úÖ 100% taxa de sucesso (6/6 documentos processados)
```

**Erros Restantes (2/37 campos):**
- `tela_sistema_1.pdf::produto`: Extra√≠do "0 CONSIGNADO" (esperado: "CONSIGNADO")
- `tela_sistema_3.pdf::total_de_parcelas`: Extra√≠do `null` (esperado: "96")

### Tech Stack Utilizado

- **Model:** GPT-5-mini (gpt-5-mini-2025-08-07)
- **Cache:** Dual-layer (.results_cache + cache/ + in-memory)
- **Embeddings:** sentence-transformers (all-MiniLM-L6-v2)
- **PDF Parsing:** PyMuPDF (fitz)
- **Pattern Matching:** Regex conservador (apenas datas m√∫ltiplas)
- **Validation:** Framework campo-a-campo (test_accuracy.py)

### Pr√≥ximos Passos

Para atingir 100% de acur√°cia e <10s consistente:
1. Investigar por que `total_de_parcelas` n√£o √© detectado (vis√≠vel na imagem)
2. Corrigir extra√ß√£o de `produto` (remover "0 extra)
3. Explorar vision models para casos edge (GPT-4-vision para PDFs com layout complexo)
4. Otimizar fingerprinting para template matching real (ignorar campos vari√°veis)

---

Desenvolvido para o **Enter AI Fellowship Challenge** üöÄ

Ian Klein
lots of energy and desire to be part of it.
